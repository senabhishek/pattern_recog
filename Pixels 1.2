
%% ******************************************************
% Pattern recognition project
% Using pixel space as feature space in two scenarios:
%         
%         -Small classes
%         -Large classes
% MG,AS,RS  
% 2013-2014, Delft TU
% *******************************************************
%% ************************
%prnist with large classes*
%**************************

a=prnist([0:9],[1:700]); %choose a large class size (more than 200 objects per class
%figure(1);
%%show(a);
%pause(5);
%close figure 1;
b=im_box(a,1,0); %add box surrounding all digits to enable the same number
                 %of features on all images
%b=im_gauss(b);%smoothing

%figure(2);
%%show(b);
%pause(5);
%close figure 2;
c=im_resize(b,[32 32]);  %resize all the data to 32 pixels (32^2 features), 
                         %feature extraction needed
%c=im_box(c,1,0);
%figure(3);
%%show(c);
%pause(5);
%close figure 3;
d=prdataset(c); %working dataset
%show(d);
len=length(d);
nrep = 4; %number of repetitions for the classifier evaluations.
improc=im_box([],1,1)*im_gauss([])*im_resize([],[32 32]);%all image mods

[Train,Test]=gendat(d,0.5); %data set split

%***************************
%Supervised classification**
%***************************

quadclass=qdc(d); %Quadratic Bayes
linclass=ldc(Train); %Linear Bayes
nmclass=nmc(Train); %nearest mean
knnclass=knnc(Train,5); %k nearest neighboor (k=10)
pznclass=parzenc(Train);%parzen classifier
perlclass=perlc(Train);
%classifier evaluations

display('No dim reduction');
err1=testc(Test,{quadclass,linclass,nmclass,knnclass,pznclass,perlclass});


%% ******************* 
%Feature extraction **
%*********************


%*********************
%Performing a PCA 64 *
%*********************

dSc=Train*scalem(Train,'variance');%scaling of the features
[W1,frac]=pcam(dSc,64); %PCA on the original dataset. Maybe a smaller N would help.
e=Train*W1; %projecting d on W1 for dim reduction
quadclass2=qdc(e); %Quadratic Bayes
linclass2=ldc(e); %Linear Bayes
nmclass2=nmc(e); %nearest mean
knnclass2=knnc(e,5); %k nearest neighboor
pznclass2=parzenc(e);%parzen classifier
perlclass2=perlc(e); %linear perceptron

%classifier evaluations

display('PCA 64');
err2=testc(Test*W1,{quadclass2,linclass2,nmclass2,knnclass2,pznclass2,perlclass2});
%************************************************
% Performing classifier combinations after PCA64*
%************************************************
%*********
%Stacked**
%*********
display('Stacking LDC, Fisher and Parzen');
S64_1=e*ldc*classc;
S64_3=e*parzenc*classc;
Stk1=[S64_1 S64_3];
Cmax1=Stk1*maxc;
Cmin1=Stk1*minc;
Cmean1=Stk1*meanc;
Cprod1=Stk1*prodc;
testc(Test*W1,{Cmax1,Cmin1,Cmean1,Cprod1});
%***********
%Sequential*
%***********
display('Sequentially applying LCD, Parzen and Fisher');
Seq64_1=ldc*classc*parzenc;
Seq64_2=fisherc*classc*parzenc;
prcrossval(e,{Seq64_1,Seq64_2},10,2);

%% *******************
%Performing a PCA 32 *
%*********************
[W2,frac2]=pcam(Train,32); %PCA on the original dataset. 
f=Train*W2; %projecting d on W1 for dim reduction
quadclass3=qdc(f); %Quadratic Bayes
linclass3=ldc(f); %Linear Bayes
nmclass3=nmc(f); %nearest mean
knnclass3=knnc(f,5); %k nearest neighboor 
pznclass3=parzenc(f);%parzen classifier
perlclass3=perlc(f); %linear perceptron

display('PCA 32');
err3=testc(Test*W2,{quadclass3,linclass3,nmclass3,knnclass3,pznclass3,perlclass3});
%it's possible that a projection to a
%32 dim subspace leaves out important
%information; by looking at the 
%results from a PCA 64, it's then
%clear that the choice of projecting
%on a 32 dim space is not the best.
%************************************************
% Performing classifier combinations after PCA32*
%************************************************
%*********
%Stacked**
%*********
display('Stacking Parzen and Fisher');
% S32_1=f*perlc*classc;
S32_2=f*fisherc*classc;
S32_3=f*parzenc*classc;
Stk2=[S32_3 S32_2];% S32_1];
Cmax2=Stk2*maxc;
Cmin2=Stk2*minc;
Cmean2=Stk2*meanc;
Cprod2=Stk2*prodc;
testc(Test*W2,{Cmax2,Cmin2,Cmean2,Cprod2});

%***********
%Sequential*
%***********
display('Sequentially applying Perceptron, Parzen and Fisher');
Seq32_1=perlc*classc*parzenc;
Seq32_2=fisherc*classc*parzenc;
prcrossval(f,{Seq32_2},10,2); 


%% *******************
%Performing a PCA 16 *
%*********************
[W3,frac2]=pcam(Train,16); %PCA on the original dataset. 
g=Train*W3; %projecting d on W1 for dim reduction
quadclass4=qdc(g); %Quadratic Bayes
linclass4=ldc(g); %Linear Bayes
nmclass4=nmc(g); %nearest mean
knnclass4=knnc(g,4); %k nearest neighboor 
pznclass4=parzenc(g);%parzen classifier
perlclass4=perlc(g); %linear perceptron

%classifier evaluations

display('PCA 16');
err4=testc(Test*W3,{quadclass4,linclass4,nmclass4,knnclass4,pznclass4,perlclass4});
%% *****************
% Error gathering***
%*******************

errorsLC={err1 err2 err3 err4};


%% *********************************************************************
%% *********************************************************************
%New test set from nist dataset using smaller class sizes(SmallDataSet)*
%***********************************************************************

SDS1=prnist([0:9],[1:200]);
figure(4);
show(SDS1);
pause(5);
close figure 4;
SDS1=im_box(SDS1,1,0); 
                 
figure(5);
show(SDS1);
pause(5);
close figure 5;
SDS1=im_resize(SDS1,[32 32]);  
                        
figure(6);
show(SDS1);
pause(5);
close figure 6;
SDS1=prdataset(SDS1); %Test dataset

[TraSC,TeSC]=gendat(SDS1,0.05);%split data set

quadclass5=qdc(TraSC); %Quadratic Bayes
linclass5=ldc(TraSC); %Linear Bayes
nmclass5=nmc(TraSC); %nearest mean
knnclass5_1=knnc(TraSC,1); %k nearest neighboor
knnclass5_2=knnc(TraSC,2); 
knnclass5_6=knnc(TraSC,6);
pznclass5=parzenc(TraSC);%parzen classifier
perlclass5=perlc(TraSC);%perceptron
svcclass5=svc(TraSC);

err5=testc(TeSC,{quadclass5,svcclass5,linclass5,knnclass5_1,knnclass5_2,knnclass5_6,nmclass5,perlclass5}); 
                                              %The error obtained here,
                                              %without projecting the
                                              %highly dimensional space is
                                              %very high, especially for
                                              %complex classifiers (think
                                              %Parzen). Dumber classifiers
                                              %such as NN perform closer to
                                              %expected 


%% **************************
% feature extraction*********
%****************************

%***********
% PCA 64 ***
%***********

TraSC1=TraSC*scalem(TraSC,'variance');%scaling of the features
[W8,frac8]=pcam(TraSC1,64); %PCA on the original dataset. 
h=TraSC1*W8;
quadclass6=qdc(h); %Quadratic Bayes
linclass6=ldc(h); %Linear Bayes
nmclass6=nmc(h); %nearest mean
knnclass6=knnc(h,2); %k nearest neighboor 
pznclass6=parzenc(h);%parzen classifier
perlclass6=perlc(h); %linear perceptron
svcclass6=svc(h); %support vector machine

display('PCA 64 on small class');

err6=testc(TeSC*W8,{quadclass6,linclass6,knnclass6,pznclass6,perlclass6,svcclass6});



%**********
% PCA 32 **
%**********

[W9,frac9]=pcam(TraSC1,32); %PCA on the original dataset. 
i=TraSC1*W9;
quadclass7=qdc(i);
linclass7=ldc(i);
nmclass7=nmc(i);
knnclass7=knnc(i,2);
pznclass7=parzenc(i);
perlclass7=perlc(i);
svcclass7=svc(i);

display('PCA 32 on small class');

err7=testc(TeSC*W9,{quadclass7,linclass7,knnclass7,pznclass7,perlclass7,nmclass7,svcclass7});

%**********
% PCA 16 **
%**********

[W10,frac10]=pcam(TraSC1,16); %PCA on the original dataset. 
j=TraSC1*W10;
quadclass8=qdc(j);
linclass8=ldc(j);
nmclass8=nmc(j);
knnclass8=knnc(j,2);
pznclass8=parzenc(j);
perlclas8=perlc(j);
svcclass8=svc(j);

display('PCA 16 on small class');

err8=testc(TeSC*W10,{quadclass8,linclass8,knnclass8,pznclass8,perlclas8,svcclass8});

%*********************************************
% Classifier combinations for small classes **
%*********************************************

display('combining classfiers on the best performing PCA proyection');

%*****************
%Stacked, PCA64 **
%*****************

display('Stacking LDC, Parzen and Fisher for a small class case, after PCA64');
% StSC_1=h*qdc*classc;
StSC_2=h*fisherc*classc;
StSC_3=h*parzenc*classc;
Stk3=[StSC_3 StSC_2];% StSC_1];
Cmax3=Stk3*maxc;
Cmin3=Stk3*minc;
Cmean3=Stk3*meanc;
Cprod3=Stk3*prodc;
err9=testc(TeSC*W8,{Cmax3,Cmin3,Cmean3,Cprod3});


%*****************
%Stacked, PCA32 **
%*****************
display('Stacking LDC, Parzen and Fisher for a small class case, after PCA32');
% StSC_4=i*qdc*classc;
StSC_5=i*fisherc*classc;
StSC_6=i*parzenc*classc;
Stk4=[StSC_6 StSC_5];% StSC_4];
Cmax4=Stk4*maxc;
Cmin4=Stk4*minc;
Cmean4=Stk4*meanc;
Cprod4=Stk4*prodc;
err10=testc(TeSC*W9,{Cmax4,Cmin4,Cmean4,Cprod4});

%% ***********************************
% Error gathering for small classes***
%*************************************

errorsSC={err5 err6 err7 err8};

